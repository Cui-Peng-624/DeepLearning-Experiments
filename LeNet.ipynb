{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c7cdd0-aba9-4719-8277-1c35dcacc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Python 标准库模块\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# 2. Python 第三方模块\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 3. 应用程序自定义模块\n",
    "from visualization import TrainingVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22270c78-8706-43f9-8749-55fe90307b58",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d170e58-7eb3-4d65-9045-aa5e97c5f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理和加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "'''\n",
    "这段代码定义了一个 transform 对象，用于对数据进行预处理。这里使用了两个预处理步骤：\n",
    "\n",
    "transforms.ToTensor():\n",
    "\n",
    "将PIL Image或numpy ndarray转换为tensor（张量），并且将像素值从0-255缩放到0-1之间。\n",
    "这个操作对于深度学习模型是必要的，因为模型期望输入是浮点型的张量。\n",
    "transforms.Normalize((0.5,), (0.5,)):\n",
    "\n",
    "对张量进行标准化处理。\n",
    "第一个参数 (0.5,) 是均值，第二个参数 (0.5,) 是标准差。它们都是针对每个通道的。\n",
    "对于Fashion MNIST数据集（灰度图像，只有一个通道），每个像素点会按公式 (x - mean) / std 进行标准化，这里将其变换为 (x - 0.5) / 0.5，即将像素值从范围 [0, 1] 变换到范围 [-1, 1]。\n",
    "'''\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c60a31-97cd-4051-9516-b18aba917a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58344b29-9583-4e72-b688-4d5aa1a1b6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader) # 总元素个数要乘上batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5473d51-8668-4a10-9d39-d211d88eb79b",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4e55cf-223e-4a87-8508-07143a814407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c16e67d4-8ca7-4a5c-8fab-01edbc85c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "model = LeNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d170170f-66a4-4028-8c84-74936e96b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和测试模型\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch, visualizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = correct / len(train_loader.dataset)\n",
    "    \n",
    "    # visualizer.add(epoch, (avg_train_loss, train_accuracy))\n",
    "    return epoch, avg_train_loss, train_accuracy\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, visualizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}'\n",
    "          f' ({test_accuracy:.0f}%)\\n')\n",
    "    \n",
    "    # visualizer.add(epoch, (None, None, test_accuracy))\n",
    "    return epoch, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccfa77a-166f-4f3c-8255-ff858cb6bcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设备配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30a03f-42fa-4313-a1cf-76a5804c30f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 0.125804\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 0.064712\n"
     ]
    }
   ],
   "source": [
    "# 初始化 TrainingVisualizer\n",
    "visualizer = TrainingVisualizer(xlabel='Epoch', ylabel='Value', title='Training and Test Metrics',\n",
    "                                legend=['Train Loss', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "# 训练和测试模型\n",
    "for epoch in range(1, 101):\n",
    "    epoch, avg_train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion, epoch, visualizer)\n",
    "    epoch, test_accuracy = test(model, device, test_loader, criterion, epoch, visualizer)\n",
    "    visualizer.add(epoch, (avg_train_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b44196-665e-41e9-9b73-9a2c38e48df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a566a50-b3aa-48fa-8dbe-014c458a9f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495f97d-02c3-4e7f-aee3-8acc05cf9c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90881b4-bb03-421e-8c1f-496782e0ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971823bf-ba1c-4084-8b4b-0a8978edb3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
