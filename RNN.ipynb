{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbe623c-63f7-4f94-b5a7-f0c390987c4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83c6ebc-ec78-4833-b7e8-f382acd5a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 检查GPU是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2a561e-d924-40c7-ab9c-1d2bf8ee65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文本数据\n",
    "with open('data/time_machine_txt/timemachine.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# 创建字符映射表\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "\n",
    "# 转换文本为索引\n",
    "text_as_int = np.array([char_to_idx[c] for c in text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efea6a1f-7d49-4877-a8f3-809fb65c1415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178979, 178979)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_as_int), text_as_int.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d15872c-6405-4b83-9576-71d282b84b74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(chars), chars\n",
    "# char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "817a41b5-2087-4f51-b5f6-c2fecd86b824",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "seq_length = 100  # 序列长度 - 一个句子100个单词\n",
    "batch_size = 512\n",
    "hidden_size = 256\n",
    "embedding_dim = 64 # input_size 嵌入向量的大小\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "vocab_size = len(chars) # 字符的个数\n",
    "\n",
    "def create_dataset(text_as_int, seq_length, batch_size):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(0, len(text_as_int) - seq_length):\n",
    "        sequences.append(text_as_int[i:i + seq_length])\n",
    "        targets.append(text_as_int[i + 1:i + seq_length + 1])\n",
    "    sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    # return sequences, targets\n",
    "    dataset = torch.utils.data.TensorDataset(sequences, targets)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = create_dataset(text_as_int, seq_length, batch_size)\n",
    "# sequences, targets = create_dataset(text_as_int, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0585287-3927-426c-accf-f5a26a79c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([178879, 100]), torch.Size([178879, 100]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f30d0ec-df57-4065-835d-bc4bbddb8c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[35, 51, 48,  1, 35, 52, 56, 48,  1, 28, 44, 46, 51, 52, 57, 48,  7,  1,\n",
       "          45, 68,  1, 23,  9,  1, 22,  9,  1, 38, 48, 55, 55, 62,  1, 41, 10, 11,\n",
       "          12, 11, 42,  0,  0,  0,  0,  0, 24,  0,  0,  0, 35, 51, 48,  1, 35, 52,\n",
       "          56, 48,  1, 35, 61, 44, 65, 48, 55, 55, 48, 61,  1,  5, 49, 58, 61,  1,\n",
       "          62, 58,  1, 52, 63,  1, 66, 52, 55, 55,  1, 45, 48,  1, 46, 58, 57, 65,\n",
       "          48, 57, 52, 48, 57, 63,  1, 63, 58,  1],\n",
       "         [51, 48,  1, 35, 52, 56, 48,  1, 28, 44, 46, 51, 52, 57, 48,  7,  1, 45,\n",
       "          68,  1, 23,  9,  1, 22,  9,  1, 38, 48, 55, 55, 62,  1, 41, 10, 11, 12,\n",
       "          11, 42,  0,  0,  0,  0,  0, 24,  0,  0,  0, 35, 51, 48,  1, 35, 52, 56,\n",
       "          48,  1, 35, 61, 44, 65, 48, 55, 55, 48, 61,  1,  5, 49, 58, 61,  1, 62,\n",
       "          58,  1, 52, 63,  1, 66, 52, 55, 55,  1, 45, 48,  1, 46, 58, 57, 65, 48,\n",
       "          57, 52, 48, 57, 63,  1, 63, 58,  1, 62]]),\n",
       " tensor([[51, 48,  1, 35, 52, 56, 48,  1, 28, 44, 46, 51, 52, 57, 48,  7,  1, 45,\n",
       "          68,  1, 23,  9,  1, 22,  9,  1, 38, 48, 55, 55, 62,  1, 41, 10, 11, 12,\n",
       "          11, 42,  0,  0,  0,  0,  0, 24,  0,  0,  0, 35, 51, 48,  1, 35, 52, 56,\n",
       "          48,  1, 35, 61, 44, 65, 48, 55, 55, 48, 61,  1,  5, 49, 58, 61,  1, 62,\n",
       "          58,  1, 52, 63,  1, 66, 52, 55, 55,  1, 45, 48,  1, 46, 58, 57, 65, 48,\n",
       "          57, 52, 48, 57, 63,  1, 63, 58,  1, 62],\n",
       "         [48,  1, 35, 52, 56, 48,  1, 28, 44, 46, 51, 52, 57, 48,  7,  1, 45, 68,\n",
       "           1, 23,  9,  1, 22,  9,  1, 38, 48, 55, 55, 62,  1, 41, 10, 11, 12, 11,\n",
       "          42,  0,  0,  0,  0,  0, 24,  0,  0,  0, 35, 51, 48,  1, 35, 52, 56, 48,\n",
       "           1, 35, 61, 44, 65, 48, 55, 55, 48, 61,  1,  5, 49, 58, 61,  1, 62, 58,\n",
       "           1, 52, 63,  1, 66, 52, 55, 55,  1, 45, 48,  1, 46, 58, 57, 65, 48, 57,\n",
       "          52, 48, 57, 63,  1, 63, 58,  1, 62, 59]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0:2, ], targets[0:2, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32d7d18f-31da-4487-b927-012e2fa21d23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Data shape: torch.Size([512, 100])\n",
      "Labels shape: torch.Size([512, 100])\n"
     ]
    }
   ],
   "source": [
    "# 遍历DataLoader并查看一个批次的数据形状\n",
    "for batch_idx, (batch_data, batch_labels) in enumerate(dataloader):\n",
    "    print(batch_idx)\n",
    "    print(\"Data shape:\", batch_data.shape)\n",
    "    print(\"Labels shape:\", batch_labels.shape)\n",
    "    break  # 只查看第一个批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab196248-dac7-4a7d-b6a5-fe5709c386ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义RNN模型\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        # print(\"***\", x.shape)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, hidden.size(2))\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(num_layers, batch_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc5d4e0e-1f0d-4765-aaff-05450f414a3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [101/350], Loss: 2.5089, Perplexity: 12.2911\n",
      "Epoch [1/10], Step [201/350], Loss: 1.8286, Perplexity: 6.2253\n",
      "Epoch [1/10], Step [301/350], Loss: 1.5851, Perplexity: 4.8799\n",
      "191\n",
      "Epoch [2/10], Step [101/350], Loss: 1.3923, Perplexity: 4.0242\n",
      "Epoch [2/10], Step [201/350], Loss: 1.2839, Perplexity: 3.6108\n",
      "Epoch [2/10], Step [301/350], Loss: 1.2067, Perplexity: 3.3426\n",
      "191\n",
      "Epoch [3/10], Step [101/350], Loss: 1.1101, Perplexity: 3.0348\n",
      "Epoch [3/10], Step [201/350], Loss: 1.0314, Perplexity: 2.8050\n",
      "Epoch [3/10], Step [301/350], Loss: 0.9667, Perplexity: 2.6292\n",
      "191\n",
      "Epoch [4/10], Step [101/350], Loss: 0.8832, Perplexity: 2.4187\n",
      "Epoch [4/10], Step [201/350], Loss: 0.8171, Perplexity: 2.2639\n",
      "Epoch [4/10], Step [301/350], Loss: 0.7649, Perplexity: 2.1488\n",
      "191\n",
      "Epoch [5/10], Step [101/350], Loss: 0.6996, Perplexity: 2.0129\n",
      "Epoch [5/10], Step [201/350], Loss: 0.6533, Perplexity: 1.9219\n",
      "Epoch [5/10], Step [301/350], Loss: 0.6173, Perplexity: 1.8540\n",
      "191\n",
      "Epoch [6/10], Step [101/350], Loss: 0.5768, Perplexity: 1.7804\n",
      "Epoch [6/10], Step [201/350], Loss: 0.5455, Perplexity: 1.7255\n",
      "Epoch [6/10], Step [301/350], Loss: 0.5246, Perplexity: 1.6897\n",
      "191\n",
      "Epoch [7/10], Step [101/350], Loss: 0.4988, Perplexity: 1.6468\n",
      "Epoch [7/10], Step [201/350], Loss: 0.4804, Perplexity: 1.6166\n",
      "Epoch [7/10], Step [301/350], Loss: 0.4680, Perplexity: 1.5967\n",
      "191\n",
      "Epoch [8/10], Step [101/350], Loss: 0.4523, Perplexity: 1.5719\n",
      "Epoch [8/10], Step [201/350], Loss: 0.4381, Perplexity: 1.5498\n",
      "Epoch [8/10], Step [301/350], Loss: 0.4300, Perplexity: 1.5373\n",
      "191\n",
      "Epoch [9/10], Step [101/350], Loss: 0.4212, Perplexity: 1.5238\n",
      "Epoch [9/10], Step [201/350], Loss: 0.4106, Perplexity: 1.5077\n",
      "Epoch [9/10], Step [301/350], Loss: 0.4041, Perplexity: 1.4980\n",
      "191\n",
      "Epoch [10/10], Step [101/350], Loss: 0.3992, Perplexity: 1.4906\n",
      "Epoch [10/10], Step [201/350], Loss: 0.3913, Perplexity: 1.4789\n",
      "Epoch [10/10], Step [301/350], Loss: 0.3873, Perplexity: 1.4730\n",
      "191\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = RNNModel(vocab_size, embedding_dim, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练模型并计算困惑度\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        \n",
    "        # inputs = inputs.view(batch_size, -1).to(device)\n",
    "        # 获取当前批次的实际大小\n",
    "        current_batch_size = inputs.size(0)\n",
    "        # if current_batch_size != 512:\n",
    "        #     print(current_batch_size)\n",
    "        inputs = inputs.view(current_batch_size, -1).to(device)\n",
    "        \n",
    "        targets = targets.view(-1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 初始化隐藏状态并将其从计算图中分离\n",
    "        # hidden = model.init_hidden(batch_size).detach()\n",
    "        hidden = model.init_hidden(current_batch_size).detach()\n",
    "        \n",
    "        output, hidden = model(inputs, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "            avg_loss = total_loss / 100\n",
    "            perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {avg_loss:.4f}, Perplexity: {perplexity:.4f}')\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd4377a1-243b-4edb-b657-dafa071b4b84",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filby became pensive. It was an altogether new element in the\n",
      "sexuritations, but simply stood rouner.\n",
      "\n",
      "'Ithe but myself and onces, the flames of the burning forest, I tried to convous sure of a\n",
      "solitys, their little eyes t\n"
     ]
    }
   ],
   "source": [
    "# 生成文本\n",
    "def generate_text(model, start_str, length):\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(1)\n",
    "    input = torch.tensor([char_to_idx[ch] for ch in start_str], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    generated_text = start_str\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input, hidden)\n",
    "        _, top_idx = torch.topk(output[-1], 1)\n",
    "        next_char = idx_to_char[top_idx.item()]\n",
    "        generated_text += next_char\n",
    "        input = torch.tensor([[top_idx]], dtype=torch.long).to(device)\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "start_str = \"Filby became pensive. \"\n",
    "generated_text = generate_text(model, start_str, 200)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1deb75-c342-42bb-9cca-c389523f35e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f283e-6085-4499-beb1-e98c7fd690ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0fe4c-b4af-414c-853a-c7189986551b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5667419-85e0-4d81-94de-ecc5748dedfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efdfe6-7208-4b3b-a0da-2a5f27f85e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d13d5-ae1a-49cc-a73c-6c5423f3f2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b8ed0-330f-440b-a3ae-91ffc6a46963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
